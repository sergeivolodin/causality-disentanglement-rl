{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\"\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from causal_analysis.helpers import get_df_from_logdir, CPU_Unpickler\n",
    "from sparse_causal_model_learner_rl.sacred_gin_tune.sacred_wrapper import load_config_files\n",
    "from sparse_causal_model_learner_rl.learners.dots_learner import DotsLearner\n",
    "from sparse_causal_model_learner_rl.config import Config\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dots']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_config_files(['../sparse_causal_model_learner_rl/configs/dots.gin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner = pickle.load(open(os.path.join(ckpt_dir, 'checkpoint_0', 'checkpoint'), 'rb'))\n",
    "learner = DotsLearner(Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLLECTING DATA!!!\n"
     ]
    }
   ],
   "source": [
    "learner.collect_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = learner._context['X_chw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLLECTING DATA!!!\n"
     ]
    }
   ],
   "source": [
    "learner.collect_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = learner._context['X_chw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.norm(data - data_test).item() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 5, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB = 3\n",
    "N_OBJ = 6\n",
    "CONV_FACTOR = 2\n",
    "COORD_FACTOR = 5\n",
    "H, W = 5, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomEncoder, self).__init__()\n",
    "        self.conv_obj = nn.Conv2d(in_channels=RGB, out_channels=N_OBJ * CONV_FACTOR, kernel_size=(1, 1))\n",
    "        # N_OBJ * CONV_FACTOR\n",
    "        self.conv_x  = nn.Conv2d(in_channels=N_OBJ * CONV_FACTOR, out_channels=N_OBJ * CONV_FACTOR, kernel_size=(H, 1),\n",
    "                                 groups=N_OBJ * CONV_FACTOR)\n",
    "        self.conv_x1 = nn.Conv2d(in_channels=N_OBJ * CONV_FACTOR, out_channels=N_OBJ * CONV_FACTOR, kernel_size=(1, W),\n",
    "                                 groups=N_OBJ * CONV_FACTOR)\n",
    "\n",
    "        \n",
    "        self.conv_y  = nn.Conv2d(in_channels=N_OBJ * CONV_FACTOR, out_channels=N_OBJ * CONV_FACTOR, kernel_size=(1, W),\n",
    "                                 groups=N_OBJ * CONV_FACTOR)\n",
    "        self.conv_y1 = nn.Conv2d(in_channels=N_OBJ * CONV_FACTOR, out_channels=N_OBJ * CONV_FACTOR, kernel_size=(H, 1),\n",
    "                                 groups=N_OBJ * CONV_FACTOR)\n",
    "#         + softmax over all positions\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_obj(x) # shape n_obj, h, w\n",
    "#         x = nn.Sigmoid(x) # objects space\n",
    "\n",
    "        x_flat = x.view(-1, N_OBJ * CONV_FACTOR, H * W)\n",
    "        x = nn.Softmax(2)(x_flat * 10).view_as(x)\n",
    "\n",
    "        x_x = self.conv_x(x) # shape 1, w\n",
    "        x_x = self.conv_x1(x_x) # shape 1, 1\n",
    "        x_x = torch.flatten(x_x, start_dim=1) # shape n_obj * factor, x-coordinate\n",
    "        \n",
    "        x_y = self.conv_y(x) # shape h, 1\n",
    "        x_y = self.conv_y1(x_y) # shape 1, 1\n",
    "        x_y = torch.flatten(x_y, start_dim=1) # shape batch, n_obj * factor\n",
    "        \n",
    "        out = torch.cat([x_x, x_y], dim=1)\n",
    "        return out\n",
    "    \n",
    "class BiasAdder(nn.Module):\n",
    "    def __init__(self, n_items, n_expand=1):\n",
    "        \"\"\"Add bias and broadcast.\n",
    "        \n",
    "        in_shape: [batch (silent), n_items]\n",
    "        out_shape: [batch, n_items, n_expand]\n",
    "        \n",
    "        weight shape: [expand] (same for every item)\n",
    "        \"\"\"\n",
    "        super(BiasAdder, self).__init__()\n",
    "        self.n_items = n_items\n",
    "        self.n_expand = n_expand\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.Tensor(n_expand,))\n",
    "        self.weight = nn.Parameter(torch.Tensor(1,))\n",
    "        torch.nn.init.zeros_(self.bias)\n",
    "        torch.nn.init.ones_(self.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 2\n",
    "#         torch.einsum('bn,z->bnz')\n",
    "        x = x.view(*x.shape, 1)\n",
    "        return (x + self.bias) * self.weight\n",
    "\n",
    "    \n",
    "class CustomDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDecoder, self).__init__()\n",
    "        \n",
    "        self.pb_x = BiasAdder(n_items=N_OBJ * CONV_FACTOR, n_expand=H * COORD_FACTOR)\n",
    "        self.pb_y = BiasAdder(n_items=N_OBJ * CONV_FACTOR, n_expand=W * COORD_FACTOR)\n",
    "        \n",
    "#         self.one_hot_x = nn.ConvTranspose2d(in_channels=N_OBJ * CONV_FACTOR, out_channels=N_OBJ * CONV_FACTOR, kernel_size=(H * COORD_FACTOR, 1))\n",
    "#         self.one_hot_y = nn.ConvTranspose2d(in_channels=N_OBJ * CONV_FACTOR, out_channels=N_OBJ * CONV_FACTOR, kernel_size=(1, W * COORD_FACTOR))\n",
    "        \n",
    "        self.one_hot_x = nn.Conv2d(in_channels=N_OBJ * CONV_FACTOR, out_channels=N_OBJ * CONV_FACTOR, kernel_size=(COORD_FACTOR, 1),\n",
    "                                   stride=(COORD_FACTOR, 1), groups=N_OBJ * CONV_FACTOR)\n",
    "        \n",
    "        self.one_hot_y = nn.Conv2d(in_channels=N_OBJ * CONV_FACTOR, out_channels=N_OBJ * CONV_FACTOR, kernel_size=(COORD_FACTOR, 1),\n",
    "                                   stride=(COORD_FACTOR, 1), groups=N_OBJ * CONV_FACTOR)\n",
    "    \n",
    "        self.to_rgb = nn.Conv2d(in_channels=N_OBJ * CONV_FACTOR, out_channels=RGB, kernel_size=(1, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xdim = x.shape[1] // 2\n",
    "        x_x = x[:, :xdim]\n",
    "        x_y = x[:, xdim:]\n",
    "        \n",
    "#         x_x = x_x.view(-1, xdim, 1, 1) # 1x1 image\n",
    "#         x_y = x_y.view(-1, xdim, 1, 1)\n",
    "        \n",
    "        pb_x = self.pb_x(x_x) # shape batch, obj*conv_factor, H * coord\n",
    "        pb_y = self.pb_y(x_y) # shape batch, obj*conv_factor, W * coord\n",
    "        \n",
    "        pb_x = nn.Sigmoid()(pb_x) # progressbar encoding\n",
    "        pb_y = nn.Sigmoid()(pb_y)\n",
    "        \n",
    "        pb_x = pb_x.view(*pb_x.shape, 1) # size x 1\n",
    "        pb_y = pb_y.view(*pb_y.shape, 1)\n",
    "        \n",
    "        oh_x = self.one_hot_x(pb_x)\n",
    "        oh_x = oh_x.view(oh_x.shape[0], N_OBJ * CONV_FACTOR, H) # size batch, obj*conv, H\n",
    "        oh_y = self.one_hot_y(pb_y)\n",
    "        oh_y = oh_y.view(oh_y.shape[0], N_OBJ * CONV_FACTOR, W) # size batch, obj*conv, W\n",
    "        \n",
    "        oh_x = nn.Softmax(2)(oh_x * 10)\n",
    "        oh_y = nn.Softmax(2)(oh_y * 10)\n",
    "        \n",
    "        oh_xy = torch.einsum('bcn,bcm->bcnm', oh_x, oh_y)\n",
    "        \n",
    "        oh_rgb = self.to_rgb(oh_xy)\n",
    "        \n",
    "        return oh_rgb\n",
    "        \n",
    "\n",
    "class CustomAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomAutoEncoder, self).__init__()\n",
    "        self.encoder = CustomEncoder()\n",
    "        self.decoder = CustomDecoder()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "ae = CustomAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(np.random.randn(10, 24))\n",
    "b = torch.from_numpy(np.ones(91,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 24, 91])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x.view(10, 24, 1) + b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841,\n",
       "        0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841,\n",
       "        0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841,\n",
       "        0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841,\n",
       "        0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841,\n",
       "        0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841,\n",
       "        0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841,\n",
       "        0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841,\n",
       "        0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841,\n",
       "        0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841, 0.9841,\n",
       "        0.9841], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('bn,z->bnz', x, b)[3, 4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obss = torch.from_numpy(np.array(np.random.randn(10, 3, 5, 5), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = CustomEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * N_OBJ * CONV_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 24])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc(obss).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no, it multiplies by a value\n",
    "# in_ch=fixed, out_ch=fixed, tensor_shape=[1,5] -- will be multiplied\n",
    "# say, x=1 -> 1 2 3 4 but need sigmoid(x-x0) -> conv size 2\n",
    "l = nn.ConvTranspose2d(in_channels=6, out_channels=6, kernel_size=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight', torch.Size([6, 6, 1, 5])), ('bias', torch.Size([6]))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], x[1].shape) for x in l.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = CustomAutoEncoder().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(ae.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fcn(y_true, y_pred):\n",
    "    delta = y_true - y_pred\n",
    "    delta = torch.abs(delta)\n",
    "    delta = delta ** 2\n",
    "    delta = torch.mean(delta, dim=0)\n",
    "    delta = torch.sum(delta)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "losses_test = []\n",
    "grads = []\n",
    "\n",
    "test_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('encoder.conv_obj.weight', torch.Size([12, 3, 1, 1])),\n",
       " ('encoder.conv_obj.bias', torch.Size([12])),\n",
       " ('encoder.conv_x.weight', torch.Size([12, 1, 5, 1])),\n",
       " ('encoder.conv_x.bias', torch.Size([12])),\n",
       " ('encoder.conv_x1.weight', torch.Size([12, 1, 1, 5])),\n",
       " ('encoder.conv_x1.bias', torch.Size([12])),\n",
       " ('encoder.conv_y.weight', torch.Size([12, 1, 1, 5])),\n",
       " ('encoder.conv_y.bias', torch.Size([12])),\n",
       " ('encoder.conv_y1.weight', torch.Size([12, 1, 5, 1])),\n",
       " ('encoder.conv_y1.bias', torch.Size([12])),\n",
       " ('decoder.pb_x.bias', torch.Size([25])),\n",
       " ('decoder.pb_x.weight', torch.Size([1])),\n",
       " ('decoder.pb_y.bias', torch.Size([25])),\n",
       " ('decoder.pb_y.weight', torch.Size([1])),\n",
       " ('decoder.one_hot_x.weight', torch.Size([12, 1, 5, 1])),\n",
       " ('decoder.one_hot_x.bias', torch.Size([12])),\n",
       " ('decoder.one_hot_y.weight', torch.Size([12, 1, 5, 1])),\n",
       " ('decoder.one_hot_y.bias', torch.Size([12])),\n",
       " ('decoder.to_rgb.weight', torch.Size([3, 12, 1, 1])),\n",
       " ('decoder.to_rgb.bias', torch.Size([3]))]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], x[1].shape) for x in ae.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fde2c2730fe4cf78f5539d7764bd94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5000)):\n",
    "    opt.zero_grad()\n",
    "    loss = loss_fcn(data, ae(data))\n",
    "    loss.backward()\n",
    "    \n",
    "    grad = [x.grad for x in ae.parameters()]\n",
    "    grad = np.max([torch.max(torch.abs(x)).item() for x in grad])\n",
    "    grads.append(grad)\n",
    "    \n",
    "    opt.step()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    losses_test.append(loss_fcn(data_test, ae(data_test)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = [x.grad for x in ae.parameters()]\n",
    "grad = np.max([torch.max(torch.abs(x)).item() for x in grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.980034351348877"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label='loss')\n",
    "plt.plot(losses_test, label='loss_test')\n",
    "\n",
    "# plt.plot(grads, label='grad')\n",
    "plt.legend()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
