{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from causal_util.collect_data import EnvDataCollector\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from sparse_causal_model_learner_rl.learner import Learner\n",
    "import gin\n",
    "from sparse_causal_model_learner_rl.sacred_gin_tune.sacred_wrapper import load_config_files\n",
    "from sparse_causal_model_learner_rl.config.config import Config\n",
    "from sparse_causal_model_learner_rl.trainable.decoder import IdentityDecoder\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5x5', 'common']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_config_files(['../keychest/config/5x5.gin', '../sparse_causal_model_learner_rl/configs/common.gin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def get_xy(steps=1000, orig_shape=True):\n",
    "# steps = 100\n",
    "# orig_shape = True\n",
    "# \"\"\"Get the dataset.\"\"\"\n",
    "# gin.bind_parameter('Config.feature_shape', None)\n",
    "# gin.bind_parameter('KeyChestEnvironment.flatten_observation', not orig_shape)\n",
    "# gin.bind_parameter('Config.env_steps', steps)\n",
    "# gin.bind_parameter('Config.decoder', None)\n",
    "# gin.bind_parameter('Config.model', None)\n",
    "# gin.bind_parameter('Config.reconstructor', None)\n",
    "# gin.bind_parameter('Config.value_predictor', None)\n",
    "# learner = Learner(Config())\n",
    "# learner.collect_steps(do_tqdm=True)\n",
    "# obs_x = learner._context.get('obs_x').cpu().numpy()\n",
    "# obs_y = learner._context.get('obs_y').cpu().numpy()\n",
    "# act_x = learner._context.get('action_x').cpu().numpy()\n",
    "\n",
    "# a\n",
    "\n",
    "# X = np.concatenate((obs_x, act_x), axis=1)\n",
    "# y = obs_y\n",
    "# return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_conv(steps=1000, orig_shape=True):\n",
    "    \"\"\"Get the dataset.\"\"\"\n",
    "    gin.bind_parameter('Config.feature_shape', None)\n",
    "    gin.bind_parameter('KeyChestEnvironment.flatten_observation', not orig_shape)\n",
    "    gin.bind_parameter('Config.env_steps', steps)\n",
    "    gin.bind_parameter('Config.decoder', None)\n",
    "    gin.bind_parameter('Config.model', None)\n",
    "    gin.bind_parameter('Config.reconstructor', None)\n",
    "    gin.bind_parameter('Config.value_predictor', None)\n",
    "    gin.bind_parameter('Config.disable_cuda', True)\n",
    "    learner = Learner(Config())\n",
    "    learner.collect_steps(do_tqdm=True)\n",
    "    obs_x = learner._context.get('obs_x').cpu().numpy()\n",
    "    obs_y = learner._context.get('obs_y').cpu().numpy()\n",
    "    act_x = learner._context.get('action_x').cpu().numpy()\n",
    "    \n",
    "    if orig_shape:\n",
    "        return obs_x, act_x, obs_y\n",
    "    else:\n",
    "        X = np.concatenate((obs_x, act_x), axis=1)\n",
    "        y = obs_y\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No class provided for trainable model\n",
      "WARNING:root:No class provided for trainable decoder\n",
      "WARNING:root:No class provided for trainable reconstructor\n",
      "WARNING:root:No class provided for trainable value_predictor\n",
      "WARNING:root:No parameters for optimizer opt1 <function Optimizer at 0x7f955d837378>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make environment KeyChest-v0 None {}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b65235bc76d41f3ace38b1941ebcb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Xo_train, Xa_train, yo_train = get_xy_conv(steps=100000, orig_shape=True)\n",
    "#Xo_test, Xa_test, yo_test = get_xy_conv(steps=10000, orig_shape=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import image_data_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No class provided for trainable model\n",
      "WARNING:root:No class provided for trainable decoder\n",
      "WARNING:root:No class provided for trainable reconstructor\n",
      "WARNING:root:No class provided for trainable value_predictor\n",
      "WARNING:root:No parameters for optimizer opt1 <function Optimizer at 0x7f955d837378>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make environment KeyChest-v0 None {}\n"
     ]
    }
   ],
   "source": [
    "learner = Learner(Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using channels last format in the env as well\n",
    "plt.imshow(learner.env.reset() @ np.random.rand(11, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((91656, 12, 7, 11), (91656, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xo_train.shape, Xa_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(Xo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 5, 2, 512)\n",
      "(?, 5, 2, 512) (?, 5120)\n",
      "(?, 12, 7, 11) (?, 12, 7, 11)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, Conv2D, Flatten, Dense, ReLU, MaxPooling2D, UpSampling2D, Conv2DTranspose, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.activations import tanh\n",
    "\n",
    "# Define two input layers\n",
    "image_input = Input((12, 7, 11))\n",
    "vector_input = Input((4,))\n",
    "\n",
    "# Convolution + Flatten for the image\n",
    "conv_layer = image_input\n",
    "\n",
    "conv_layer = Conv2D(512, (3, 3), padding='valid')(conv_layer)\n",
    "conv_layer = MaxPooling2D()(conv_layer)\n",
    "print(conv_layer.shape)\n",
    "conv_layer = ReLU()(conv_layer)\n",
    "# conv_layer = Conv2D(64, (5, 5), padding='same')(conv_layer)\n",
    "\n",
    "# print(conv_layer.shape)\n",
    "\n",
    "# conv_layer = Conv2D(1024, (2, 2))(conv_layer)\n",
    "# conv_layer = MaxPooling2D((2, 2), padding='valid')(conv_layer)\n",
    "# conv_layer = ReLU()(conv_layer)\n",
    "\n",
    "flat_layer = Flatten()(conv_layer)\n",
    "\n",
    "print(conv_layer.shape, flat_layer.shape)\n",
    "\n",
    "# Concatenate the convolutional features and the vector input\n",
    "# concat_layer = Concatenate()([vector_input, flat_layer])\n",
    "concat_layer = flat_layer\n",
    "middle = Dense(1024)(concat_layer)\n",
    "middle = ReLU()(middle)\n",
    "mean = Dense(2688)(middle)\n",
    "logvar = Dense(2688)(middle)\n",
    "\n",
    "middle = Sampling()([mean, logvar])\n",
    "\n",
    "upsample = Reshape((12, 7, 32))(middle)\n",
    "\n",
    "# upsample = UpSampling2D()(upsample)\n",
    "# upsample = Conv2DTranspose(512, (2, 2))(upsample)\n",
    "# upsample = ReLU()(upsample)\n",
    "\n",
    "# print(upsample.shape)\n",
    "\n",
    "# upsample = UpSampling2D((2, 2))(upsample)\n",
    "# print(upsample.shape)\n",
    "upsample = Conv2DTranspose(11, (3, 3), padding='same')(upsample)\n",
    "# upsample = ReLU()(upsample)\n",
    "\n",
    "# print(upsample.shape)\n",
    "\n",
    "# define a model with a list of two inputs\n",
    "model = Model(inputs=[image_input], outputs=upsample)\n",
    "\n",
    "print(upsample.shape, image_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.predict([Xo_train[:10], Xa_train[:10]]).shape[1:] == yo_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 91656 samples\n",
      "Epoch 1/100\n",
      "91656/91656 [==============================] - 15s 164us/sample - loss: 0.0167\n",
      "Epoch 2/100\n",
      "91656/91656 [==============================] - 15s 163us/sample - loss: 0.0025\n",
      "Epoch 3/100\n",
      "91656/91656 [==============================] - 15s 160us/sample - loss: 8.3045e-04\n",
      "Epoch 4/100\n",
      "77952/91656 [========================>.....] - ETA: 2s - loss: 4.7299e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5d5a6f44caf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fitting on inputs...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXo_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXa_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXo_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fitting on inputs...\n",
    "model.fit([Xo_train, Xa_train], Xo_train, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs1 = model.predict([Xo_train[0:1], Xa_train[0:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using channels last format in the env as well\n",
    "plt.imshow(obs1[0, :, :, :] @ np.random.rand(11, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC model -- doesn't work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([Xtrain, ytrain, Xtest, ytest], open('dataset.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, ytrain, Xtest, ytest = pickle.load(open('dataset.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No class provided for trainable value_predictor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make environment KeyChest-v0 None {}\n"
     ]
    }
   ],
   "source": [
    "gin.bind_parameter('Config.env_steps', 10)\n",
    "gin.bind_parameter('Config.disable_cuda', True)\n",
    "learner = Learner(Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = learner.env\n",
    "h, w, c = env.engine._observation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = list(range(len(Xtrain)))\n",
    "np.random.shuffle(idxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forgot to shuffle the dataset...\n",
    "Xtrain = Xtrain[idxes]\n",
    "ytrain = ytrain[idxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747M\tdataset.pkl\n"
     ]
    }
   ],
   "source": [
    "!du -s --si dataset.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(Xtrain.shape[1],), activation='tanh', kernel_initializer='glorot_normal'),\n",
    "    tf.keras.layers.Dense(64, activation='tanh', kernel_initializer='glorot_normal'),\n",
    "    tf.keras.layers.Dense(64, activation='tanh', kernel_initializer='glorot_normal'),\n",
    "    tf.keras.layers.Dense(2048, activation='tanh', kernel_initializer='glorot_normal'),\n",
    "    tf.keras.layers.Dense(2048, activation='tanh', kernel_initializer='glorot_normal'),\n",
    "    tf.keras.layers.Dense(ytrain.shape[1], activation='sigmoid', kernel_initializer='glorot_normal')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', 'binary_crossentropy', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 91632 samples, validate on 9184 samples\n",
      "Epoch 1/100\n",
      "91632/91632 [==============================] - 49s 533us/sample - loss: 0.0187 - mean_squared_error: 0.0047 - mean_absolute_error: 0.0097 - val_loss: 0.0074 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0039\n",
      "Epoch 2/100\n",
      "91632/91632 [==============================] - 50s 543us/sample - loss: 0.0041 - mean_squared_error: 9.6965e-04 - mean_absolute_error: 0.0021 - val_loss: 0.0043 - val_mean_squared_error: 0.0010 - val_mean_absolute_error: 0.0020\n",
      "Epoch 3/100\n",
      "91632/91632 [==============================] - 43s 465us/sample - loss: 0.0033 - mean_squared_error: 7.8184e-04 - mean_absolute_error: 0.0015 - val_loss: 0.0039 - val_mean_squared_error: 9.1098e-04 - val_mean_absolute_error: 0.0017\n",
      "Epoch 4/100\n",
      "91632/91632 [==============================] - 46s 504us/sample - loss: 0.0031 - mean_squared_error: 7.3046e-04 - mean_absolute_error: 0.0014 - val_loss: 0.0039 - val_mean_squared_error: 8.9386e-04 - val_mean_absolute_error: 0.0015\n",
      "Epoch 5/100\n",
      "91632/91632 [==============================] - 44s 485us/sample - loss: 0.0029 - mean_squared_error: 7.0186e-04 - mean_absolute_error: 0.0013 - val_loss: 0.0043 - val_mean_squared_error: 0.0010 - val_mean_absolute_error: 0.0017\n",
      "Epoch 6/100\n",
      "91632/91632 [==============================] - 46s 502us/sample - loss: 0.0029 - mean_squared_error: 6.9889e-04 - mean_absolute_error: 0.0012 - val_loss: 0.0044 - val_mean_squared_error: 0.0010 - val_mean_absolute_error: 0.0017\n",
      "Epoch 7/100\n",
      "91632/91632 [==============================] - 76s 832us/sample - loss: 0.0029 - mean_squared_error: 6.9188e-04 - mean_absolute_error: 0.0012 - val_loss: 0.0045 - val_mean_squared_error: 0.0010 - val_mean_absolute_error: 0.0016\n",
      "Epoch 8/100\n",
      "91632/91632 [==============================] - 57s 623us/sample - loss: 0.0029 - mean_squared_error: 6.9808e-04 - mean_absolute_error: 0.0012 - val_loss: 0.0044 - val_mean_squared_error: 9.8395e-04 - val_mean_absolute_error: 0.0016\n",
      "Epoch 9/100\n",
      "91632/91632 [==============================] - 48s 526us/sample - loss: 0.0029 - mean_squared_error: 6.9418e-04 - mean_absolute_error: 0.0012 - val_loss: 0.0047 - val_mean_squared_error: 0.0010 - val_mean_absolute_error: 0.0015\n",
      "Epoch 10/100\n",
      "91632/91632 [==============================] - 43s 473us/sample - loss: 0.0029 - mean_squared_error: 6.9066e-04 - mean_absolute_error: 0.0012 - val_loss: 0.0048 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0017\n",
      "Epoch 11/100\n",
      "91632/91632 [==============================] - 46s 501us/sample - loss: 0.0029 - mean_squared_error: 6.9220e-04 - mean_absolute_error: 0.0012 - val_loss: 0.0046 - val_mean_squared_error: 0.0010 - val_mean_absolute_error: 0.0016\n",
      "Epoch 12/100\n",
      "91632/91632 [==============================] - 47s 517us/sample - loss: 0.0029 - mean_squared_error: 6.9606e-04 - mean_absolute_error: 0.0012 - val_loss: 0.0047 - val_mean_squared_error: 0.0010 - val_mean_absolute_error: 0.0015\n",
      "Epoch 13/100\n",
      "91632/91632 [==============================] - 50s 546us/sample - loss: 0.0029 - mean_squared_error: 6.9798e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0045 - val_mean_squared_error: 9.5969e-04 - val_mean_absolute_error: 0.0014\n",
      "Epoch 14/100\n",
      "91632/91632 [==============================] - 59s 640us/sample - loss: 0.0029 - mean_squared_error: 6.9694e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0047 - val_mean_squared_error: 9.9997e-04 - val_mean_absolute_error: 0.0014\n",
      "Epoch 15/100\n",
      "91632/91632 [==============================] - 63s 692us/sample - loss: 0.0029 - mean_squared_error: 7.0028e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0052 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0017\n",
      "Epoch 16/100\n",
      "91632/91632 [==============================] - 56s 615us/sample - loss: 0.0029 - mean_squared_error: 6.9962e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0053 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0017\n",
      "Epoch 17/100\n",
      "91632/91632 [==============================] - 51s 561us/sample - loss: 0.0029 - mean_squared_error: 6.9565e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0051 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0016\n",
      "Epoch 18/100\n",
      "91632/91632 [==============================] - 62s 674us/sample - loss: 0.0030 - mean_squared_error: 7.0381e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0052 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0016\n",
      "Epoch 19/100\n",
      "91632/91632 [==============================] - 52s 571us/sample - loss: 0.0030 - mean_squared_error: 7.0217e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0058 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0017\n",
      "Epoch 20/100\n",
      "91632/91632 [==============================] - 57s 623us/sample - loss: 0.0030 - mean_squared_error: 7.0763e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0052 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0015\n",
      "Epoch 21/100\n",
      "91632/91632 [==============================] - 56s 610us/sample - loss: 0.0030 - mean_squared_error: 7.0518e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0058 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0017\n",
      "Epoch 22/100\n",
      "91632/91632 [==============================] - 55s 597us/sample - loss: 0.0030 - mean_squared_error: 7.0647e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0052 - val_mean_squared_error: 0.0010 - val_mean_absolute_error: 0.0015\n",
      "Epoch 23/100\n",
      "91632/91632 [==============================] - 45s 495us/sample - loss: 0.0031 - mean_squared_error: 7.2081e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0054 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0016\n",
      "Epoch 24/100\n",
      "91632/91632 [==============================] - 48s 520us/sample - loss: 0.0030 - mean_squared_error: 7.0438e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0058 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0017\n",
      "Epoch 25/100\n",
      "91632/91632 [==============================] - 46s 500us/sample - loss: 0.0031 - mean_squared_error: 7.1141e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0066 - val_mean_squared_error: 0.0013 - val_mean_absolute_error: 0.0018\n",
      "Epoch 26/100\n",
      "91632/91632 [==============================] - 44s 476us/sample - loss: 0.0030 - mean_squared_error: 7.0575e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0059 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0017\n",
      "Epoch 27/100\n",
      "91632/91632 [==============================] - 45s 488us/sample - loss: 0.0031 - mean_squared_error: 7.1982e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0058 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0016\n",
      "Epoch 28/100\n",
      "91632/91632 [==============================] - 61s 669us/sample - loss: 0.0031 - mean_squared_error: 7.1174e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0064 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0017\n",
      "Epoch 29/100\n",
      "91632/91632 [==============================] - 50s 550us/sample - loss: 0.0031 - mean_squared_error: 7.1059e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0058 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0015\n",
      "Epoch 30/100\n",
      "91632/91632 [==============================] - 54s 586us/sample - loss: 0.0031 - mean_squared_error: 7.1056e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0059 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0016\n",
      "Epoch 31/100\n",
      "91632/91632 [==============================] - 58s 632us/sample - loss: 0.0031 - mean_squared_error: 7.1064e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0062 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0017\n",
      "Epoch 32/100\n",
      "91632/91632 [==============================] - 46s 499us/sample - loss: 0.0031 - mean_squared_error: 7.0487e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0058 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0016\n",
      "Epoch 33/100\n",
      "91632/91632 [==============================] - 52s 567us/sample - loss: 0.0031 - mean_squared_error: 7.0439e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0058 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0015\n",
      "Epoch 34/100\n",
      "91632/91632 [==============================] - 51s 556us/sample - loss: 0.0032 - mean_squared_error: 7.2283e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0060 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0017\n",
      "Epoch 35/100\n",
      "91632/91632 [==============================] - 47s 515us/sample - loss: 0.0031 - mean_squared_error: 7.1496e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0058 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0015\n",
      "Epoch 36/100\n",
      "91632/91632 [==============================] - 51s 560us/sample - loss: 0.0032 - mean_squared_error: 7.1891e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0064 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0017\n",
      "Epoch 37/100\n",
      "91632/91632 [==============================] - 49s 532us/sample - loss: 0.0031 - mean_squared_error: 7.0627e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0069 - val_mean_squared_error: 0.0013 - val_mean_absolute_error: 0.0018\n",
      "Epoch 38/100\n",
      "91632/91632 [==============================] - 49s 535us/sample - loss: 0.0031 - mean_squared_error: 7.1621e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0073 - val_mean_squared_error: 0.0014 - val_mean_absolute_error: 0.0019\n",
      "Epoch 39/100\n",
      "91632/91632 [==============================] - 56s 610us/sample - loss: 0.0032 - mean_squared_error: 7.1597e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0064 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0016\n",
      "Epoch 40/100\n",
      "91632/91632 [==============================] - 54s 584us/sample - loss: 0.0031 - mean_squared_error: 7.0334e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0064 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0016\n",
      "Epoch 41/100\n",
      "91632/91632 [==============================] - 51s 558us/sample - loss: 0.0031 - mean_squared_error: 7.1332e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0060 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0015\n",
      "Epoch 42/100\n",
      "91632/91632 [==============================] - 48s 524us/sample - loss: 0.0031 - mean_squared_error: 7.0741e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0063 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0016\n",
      "Epoch 43/100\n",
      "91632/91632 [==============================] - 46s 497us/sample - loss: 0.0031 - mean_squared_error: 7.0755e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0065 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0016\n",
      "Epoch 44/100\n",
      "91632/91632 [==============================] - 44s 483us/sample - loss: 0.0031 - mean_squared_error: 7.1014e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0070 - val_mean_squared_error: 0.0013 - val_mean_absolute_error: 0.0017\n",
      "Epoch 45/100\n",
      "91632/91632 [==============================] - 47s 515us/sample - loss: 0.0031 - mean_squared_error: 7.1183e-04 - mean_absolute_error: 0.0011 - val_loss: 0.0065 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0016\n",
      "Epoch 46/100\n",
      "63136/91632 [===================>..........] - ETA: 15s - loss: 0.0031 - mean_squared_error: 6.9696e-04 - mean_absolute_error: 0.0011"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-5eadf624ca97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, validation_data=(Xtest, ytest), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
