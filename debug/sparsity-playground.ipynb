{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\"\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from encoder.digit_encoder import small_int_vector_asimage\n",
    "from sparse_causal_model_learner_rl.trainable.combined import FCCombinedModel\n",
    "from sparse_causal_model_learner_rl.loss.losses import manual_switch_gradient\n",
    "from sparse_causal_model_learner_rl.trainable.gumbel_switch import WithInputSwitch, LearnableSwitchSimple\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from causal_util.helpers import lstdct2dctlst\n",
    "from math import ceil\n",
    "import gin\n",
    "gin.enter_interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faaa9319828>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAAD4CAYAAACHQt+IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKrElEQVR4nO3d24tdhR3F8bWcTOu1lcZQkkxofFBBRBIZAiVFSopNrKJ9VNCHUshLLZEWRPtS/AfEl1IISVqL1iBeQMR2KhixQr1M4nhJoiFIilFLYkQ0FbzE1Yc5D6lk5vzSnn323vH7gcGZOYczC5l8s8/eZzJOIgDAcGe1PQAA+oJgAkARwQSAIoIJAEUEEwCKljTxoBd9ZyKrV0028dDomQOvntv2hLJLr/yk7QnogENvf673PzjhU93WSDBXr5rUizOrmnho9MzGFWvanlA2MzPX9gR0wLqNby94G0/JAaCIYAJAEcEEgCKCCQBFBBMAiggmABQRTAAoIpgAUEQwAaCIYAJAEcEEgCKCCQBFBBMAiggmABQRTAAoIpgAUEQwAaCoFEzbm2y/afug7TubHgUAXTQ0mLYnJP1O0rWSLpd0s+3Lmx4GAF1TOcJcJ+lgkreSfCZpp6Qbm50FAN1TCeZKSSf/VqDDg8/9F9ubbc/anj167MSo9gFAZ4zsok+SrUmmk0wvWzoxqocFgM6oBPMdSSf/ztypwecA4GulEsyXJF1i+2Lb35B0k6THm50FAN2zZNgdknxh+zZJM5ImJO1IsrfxZQDQMUODKUlJnpT0ZMNbAKDT+EkfACgimABQRDABoIhgAkARwQSAIoIJAEUEEwCKCCYAFBFMACgimABQRDABoIhgAkARwQSAIoIJAEUEEwCKCCYAFJX+AeEz2cYVa9qeAPxP+N5txoEcW/A2jjABoIhgAkARwQSAIoIJAEUEEwCKCCYAFBFMACgimABQRDABoIhgAkARwQSAIoIJAEUEEwCKCCYAFBFMACgimABQRDABoGhoMG3vsH3E9uvjGAQAXVU5wvyjpE0N7wCAzhsazCTPSvpgDFsAoNM4hwkARSMLpu3Ntmdtzx49dmJUDwsAnTGyYCbZmmQ6yfSypROjelgA6AyekgNAUeVlRQ9K+oeky2wftv3z5mcBQPcsGXaHJDePYwgAdB1PyQGgiGACQBHBBIAiggkARQQTAIoIJgAUEUwAKCKYAFBEMAGgiGACQBHBBIAiggkARQQTAIoIJgAUEUwAKCKYAFA09B8QPtPNvDvX9oQz2sYVa9qecMbie7cZ6zZ+suBtHGECQBHBBIAiggkARQQTAIoIJgAUEUwAKCKYAFBEMAGgiGACQBHBBIAiggkARQQTAIoIJgAUEUwAKCKYAFBEMAGgiGACQBHBBICiocG0vcr2Ltv7bO+1vWUcwwCgayq/0+cLSb9Ossf2BZJ2234qyb6GtwFApww9wkzyXpI9g/c/lrRf0sqmhwFA15zWOUzbqyWtlfTCKW7bbHvW9uzRYydGNA8AuqMcTNvnS3pE0u1JPvrq7Um2JplOMr1s6cQoNwJAJ5SCaXtS87F8IMmjzU4CgG6qXCW3pO2S9ie5p/lJANBNlSPM9ZJulbTB9tzg7ScN7wKAzhn6sqIkz0nyGLYAQKfxkz4AUEQwAaCIYAJAEcEEgCKCCQBFBBMAiggmABQRTAAoIpgAUEQwAaCIYAJAEcEEgCKCCQBFBBMAiggmABQRTAAoqvxe8tN24NVztXHFmiYe+mtv5t25tiegI/r0Z+xM+b7lCBMAiggmABQRTAAoIpgAUEQwAaCIYAJAEcEEgCKCCQBFBBMAiggmABQRTAAoIpgAUEQwAaCIYAJAEcEEgCKCCQBFBBMAioYG0/bZtl+0/YrtvbbvHscwAOiayq+o+FTShiTHbU9Kes72X5I83/A2AOiUocFMEknHBx9ODt7S5CgA6KLSOUzbE7bnJB2R9FSSFxpdBQAdVApmkhNJ1kiakrTO9hVfvY/tzbZnbc9+rk9HPBMA2ndaV8mTfChpl6RNp7hta5LpJNOT+uaI5gFAd1Suki+zfeHg/XMkXSPpjYZ3AUDnVK6SL5d0n+0JzQf2oSRPNDsLALqncpX8VUlrx7AFADqNn/QBgCKCCQBFBBMAiggmABQRTAAoIpgAUEQwAaCIYAJAEcEEgCKCCQBFBBMAiggmABQRTAAoIpgAUEQwAaCIYAJAUeVfXD9tl175iWZm5pp4aAADM+/OtT3ha4cjTAAoIpgAUEQwAaCIYAJAEcEEgCKCCQBFBBMAiggmABQRTAAoIpgAUEQwAaCIYAJAEcEEgCKCCQBFBBMAiggmABQRTAAoIpgAUFQOpu0J2y/bfqLJQQDQVadzhLlF0v6mhgBA15WCaXtK0nWStjU7BwC6q3qEea+kOyR9udAdbG+2PWt79uixE6PYBgCdMjSYtq+XdCTJ7sXul2Rrkukk08uWToxsIAB0ReUIc72kG2wfkrRT0gbb9ze6CgA6aGgwk9yVZCrJakk3SXo6yS2NLwOAjuF1mABQtOR07pzkGUnPNLIEADqOI0wAKCKYAFBEMAGgiGACQBHBBIAiggkARQQTAIoIJgAUEUwAKCKYAFBEMAGgiGACQBHBBIAiggkARQQTAIoIJgAUOcnoH9Q+KumfI37YiyS9P+LHbFKf9vZpq9SvvX3aKvVrb1Nbv5dk2aluaCSYTbA9m2S67R1Vfdrbp61Sv/b2aavUr71tbOUpOQAUEUwAKOpTMLe2PeA09Wlvn7ZK/drbp61Sv/aOfWtvzmECQNv6dIQJAK0imABQ1Itg2t5k+03bB23f2faexdjeYfuI7dfb3jKM7VW2d9neZ3uv7S1tb1qI7bNtv2j7lcHWu9veVGF7wvbLtp9oe8tibB+y/ZrtOduzbe8ZxvaFth+2/Ybt/ba/P5av2/VzmLYnJB2QdI2kw5JeknRzkn2tDluA7aslHZf0pyRXtL1nMbaXS1qeZI/tCyTtlvTTLv6/tW1J5yU5bntS0nOStiR5vuVpi7L9K0nTkr6V5Pq29yzE9iFJ00l68aJ12/dJ+nuSbba/IencJB82/XX7cIS5TtLBJG8l+UzSTkk3trxpQUmelfRB2zsqkryXZM/g/Y8l7Ze0st1Vp5Z5xwcfTg7eOv23ve0pSddJ2tb2ljOJ7W9LulrSdklK8tk4Yin1I5grJb190seH1dE/1H1me7WktZJeaHnKggZPb+ckHZH0VJLObh24V9Idkr5seUdFJP3N9m7bm9seM8TFko5K+sPgdMc22+eN4wv3IZhomO3zJT0i6fYkH7W9ZyFJTiRZI2lK0jrbnT3lYft6SUeS7G57S9EPklwl6VpJvxicWuqqJZKukvT7JGsl/VvSWK5t9CGY70haddLHU4PPYQQG5wMfkfRAkkfb3lMxePq1S9KmlqcsZr2kGwbnBndK2mD7/nYnLSzJO4P/HpH0mOZPhXXVYUmHT3qG8bDmA9q4PgTzJUmX2L54cHL3JkmPt7zpjDC4kLJd0v4k97S9ZzG2l9m+cPD+OZq/CPhGq6MWkeSuJFNJVmv+e/bpJLe0POuUbJ83uOinwVPbH0vq7Ks8kvxL0tu2Lxt86keSxnKhcsk4vsj/I8kXtm+TNCNpQtKOJHtbnrUg2w9K+qGki2wflvTbJNvbXbWg9ZJulfTa4NygJP0myZPtTVrQckn3DV41cZakh5J0+qU6PfJdSY/N//2pJZL+nOSv7U4a6peSHhgcRL0l6Wfj+KKdf1kRAHRFH56SA0AnEEwAKCKYAFBEMAGgiGACQBHBBIAiggkARf8BRPlhkHxYblsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(small_int_vector_asimage([5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "features = [(x, y) for x in torch.arange(10) for y in torch.arange(10)] * 5\n",
    "print(len(features))\n",
    "obs = torch.from_numpy(np.array([small_int_vector_asimage([int(t1), int(t2)]) for t1, t2 in features], dtype=np.float32)).to(device).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = list(range(len(obs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idxes_perm = idxes[1:] + idxes[0:1]\n",
    "# idxes_perm, idxes\n",
    "features_perm = [(y, x) for x, y in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_next = torch.from_numpy(np.array([small_int_vector_asimage([int(t1), int(t2)]) for t1, t2 in features_perm], dtype=np.float32)).to(device).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faaa92f0a90>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 5\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(obs[idx].detach().cpu().numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(obs_next[idx].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4004, 0.4004, 0.4004, 1.0000, 0.4004, 0.4004, 0.4004],\n",
       "         [0.4904, 0.3003, 0.4587, 1.0000, 0.4904, 0.3003, 0.4587],\n",
       "         [0.4004, 0.4004, 0.3003, 1.0000, 0.4004, 0.4004, 0.3003],\n",
       "         [0.4904, 0.3003, 0.4004, 1.0000, 0.4904, 0.3003, 0.4004],\n",
       "         [0.5005, 0.4904, 0.4004, 1.0000, 0.5005, 0.4904, 0.4004]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_std = obs.std(0, keepdim=True)\n",
    "obs_std = torch.where(obs_std < 1e-8, torch.ones_like(obs_std), obs_std)\n",
    "obs_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 7]) 35\n"
     ]
    }
   ],
   "source": [
    "shape = obs.shape[1:]\n",
    "size = np.prod(shape)\n",
    "print(shape, size)\n",
    "n_f = 3\n",
    "min_proba = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False]\n",
      "[35, 50, 50, 1] 3\n",
      "[False, False, False]\n",
      "[3, 50, 50, 1] 35\n",
      "[False, False, False, False]\n",
      "[6, 50, 50, 25, 1] 3\n"
     ]
    }
   ],
   "source": [
    "class WithInputFC(nn.Module):\n",
    "    def __init__(self, m, n_units):\n",
    "        super(WithInputFC, self).__init__()\n",
    "        self.m = m\n",
    "        self.bn = nn.BatchNorm1d(n_units)\n",
    "        self.fc1 = nn.Linear(n_units, n_units)\n",
    "#         self.fc1.weight.data[:] = torch.eye(3)\n",
    "#         self.fc1.bias.data[:] = 0\n",
    "    def forward(self, x):\n",
    "#         x = self.bn(x)\n",
    "        x = self.fc1(x)# + x\n",
    "        x = self.m(x)\n",
    "        return x\n",
    "    \n",
    "class WithOutputFC(nn.Module):\n",
    "    def __init__(self, m, n_units):\n",
    "        super(WithOutputFC, self).__init__()\n",
    "        self.m = m\n",
    "        self.fc1 = nn.Linear(n_units, n_units)\n",
    "#         self.fc1.weight.data[:] = 0\n",
    "#         self.fc1.bias.data[:] = 0\n",
    "#         self.fc1 = FCCombinedModel(input_shape=(n_units,),\n",
    "#                                    output_shape=(n_units,),\n",
    "#                                    hidden_sizes=[],\n",
    "#                                    activation_cls=None,\n",
    "#                                    input_reshape=True)\n",
    "        self.bn = nn.BatchNorm1d(n_units)\n",
    "    def forward(self, x):\n",
    "        x = self.m(x)\n",
    "#         x = self.bn(x)\n",
    "        x = self.fc1(x)# + x\n",
    "        return x\n",
    "    \n",
    "class WithLinTransform(nn.Module):\n",
    "    def __init__(self, m, n_units):\n",
    "        super(WithLinTransform, self).__init__()\n",
    "        self.model = m\n",
    "        self.n_features = n_f\n",
    "        self.n_actions = 0\n",
    "        self.n_additional_features = 0\n",
    "        self.fc1 = nn.Linear(n_units, n_units)\n",
    "        self.fc2 = nn.Linear(n_units, n_units)\n",
    "        self.fc1.weight.data[:] += torch.eye(n_units)\n",
    "        self.fc1.bias.data[:] = 0.0\n",
    "\n",
    "#     def project(self):\n",
    "#         M = self.fc1.weight\n",
    "#         M.data = torch.clamp(M, -1, 1)\n",
    "# #         M.data[M.data < -1] = -1.\n",
    "# #         M.data[M.data > 1] = 1.\n",
    "        \n",
    "    def forward(self, x, detach_rotate=False, **kwargs):\n",
    "        # shape: batch, features\n",
    "#         self.project()\n",
    "        \n",
    "#         M = self.fc1.weight\n",
    "#         A = (M - M.t()) / 2\n",
    "#         I = torch.eye(self.n_features, device=M.device)\n",
    "#         print(A, I - A)\n",
    "#         S = (I + A) @ torch.pinverse(I - A)\n",
    "#         Sinv = (I - A) @ torch.pinverse(I + A)\n",
    "        M = self.fc1.weight\n",
    "\n",
    "        if detach_rotate:\n",
    "            M = M.detach()\n",
    "#         M = M + \n",
    "#         S = nn.Softmax(1)(M)\n",
    "#\n",
    "        Sinv = torch.pinverse(M)#.detach()\n",
    "        \n",
    "        x = (x @ M) + self.fc1.bias\n",
    "        x = self.model(x, **kwargs)\n",
    "        x = (x - self.fc1.bias) @ Sinv#nn.Softmax(1)(self.fc1.weight)\n",
    "        return x\n",
    "        \n",
    "    \n",
    "dec = FCCombinedModel(input_reshape=True,#WithOutputFC(\n",
    "                      add_input_batchnorm=True,\n",
    "                      input_shape=(size,),\n",
    "                      output_shape=(n_f,),\n",
    "                      hidden_sizes=[50, 50],\n",
    "                      activation_cls=nn.LeakyReLU).to(device)#, n_f).cuda()\n",
    "rec = FCCombinedModel(input_reshape=True, #WithInputFC(\n",
    "                      input_shape=(n_f,),\n",
    "                      output_shape=(size,),\n",
    "                      add_input_batchnorm=True,\n",
    "                      hidden_sizes=[50, 50],\n",
    "                      activation_cls=nn.LeakyReLU).to(device)#, n_f).cuda()\n",
    "model = WithLinTransform(WithInputSwitch(model_cls=partial(FCCombinedModel,\n",
    "                                          output_shape=(1,),\n",
    "                                          add_input_batchnorm=True,\n",
    "                                          hidden_sizes=[50, 50, 25],\n",
    "                                          activation_cls=nn.LeakyReLU),\n",
    "                        input_shape=(n_f,),\n",
    "                        switch_cls=partial(LearnableSwitchSimple, initial_proba=min_proba,\n",
    "                                           min_proba=min_proba),\n",
    "                        give_mask=True,\n",
    "                        n_models=n_f), n_f).to(device)\n",
    "\n",
    "class MM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.n_features = n_f\n",
    "        self.n_actions = 0\n",
    "        self.n_additional_features = 0\n",
    "# model_ = MM(model)\n",
    "model_ = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.6950, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rec(dec(obs.flatten(start_dim=1))).view(obs.shape[0], *shape) - obs).flatten(start_dim=1).pow(2).sum(1).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gin.configurable\n",
    "def manual_switch_gradient(loss_delta_noreduce, model, loss_scale=1.0,\n",
    "                           eps=1e-5):\n",
    "    \"\"\"Fill in the gradient of switch probas manually\n",
    "\n",
    "    Assuming that the batch size is enough to estimate mean loss with\n",
    "     p on and off.\n",
    "    \"\"\"\n",
    "    mask = model.model.last_mask\n",
    "    input_dim = model.n_features + model.n_actions\n",
    "    output_dim = model.n_features + model.n_additional_features\n",
    "\n",
    "    delta = loss_delta_noreduce\n",
    "\n",
    "    # if have two dimensions, assuming delta in the form of (batch, n_output_features)\n",
    "    if len(delta.shape) == 2:\n",
    "        delta_expanded = delta.view(delta.shape[0], 1, delta.shape[1]).expand(-1, input_dim, -1)\n",
    "    elif len(delta.shape) == 1:  # assuming shape (batch, )\n",
    "        delta_expanded = delta.view(delta.shape[0], 1, 1).expand(-1, input_dim, output_dim)\n",
    "    mask_coeff = (mask - 0.5) * 2\n",
    "\n",
    "    mask_pos = mask\n",
    "    mask_neg = 1 - mask\n",
    "    n_pos = (mask_coeff > 0).sum(dim=0) + eps\n",
    "    n_neg = (mask_coeff < 0).sum(dim=0) + eps\n",
    "\n",
    "    mask_pos = mask_pos / n_pos\n",
    "    mask_neg = mask_neg / n_neg\n",
    "\n",
    "    mask_atleast = ((n_pos >= 1) * (n_neg >= 1))\n",
    "    mask_coeff = mask_atleast * (mask_pos - mask_neg)\n",
    "    p_grad = (delta_expanded * mask_coeff).sum(dim=0)\n",
    "    \n",
    "#     val = 0.01\n",
    "#     p_grad = torch.where(p_grad > 0.1, torch.ones_like(p_grad) * val,\n",
    "#                          -torch.ones_like(p_grad) * val)\n",
    "\n",
    "    p_grad = p_grad * loss_scale\n",
    "    \n",
    "\n",
    "    if model.model.switch.probas.grad is None:\n",
    "        model.model.switch.probas.grad = p_grad.clone()\n",
    "    else:\n",
    "        model.model.switch.probas.grad += p_grad.clone()\n",
    "\n",
    "#     model_.model.switch.probas.data[:] = 0\n",
    "#     model_.model.switch.probas.data[0, 0] = 1.0\n",
    "    return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 ** (-model_.model.last_mask.flatten(start_dim=1).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_std(t, eps=1e-8):\n",
    "    s = t.std(0, keepdim=True)\n",
    "    s = torch.where(s < eps, torch.ones_like(s), s)\n",
    "    return s\n",
    "\n",
    "def rec_loss_std(obs, obs_rec, nomean=False):\n",
    "    delta = (obs - obs_rec)\n",
    "    delta = delta / obs_std\n",
    "    loss = delta.flatten(start_dim=1).pow(2).sum(1)\n",
    "    if not nomean:\n",
    "        loss = loss.mean(0)\n",
    "    return loss\n",
    "\n",
    "def acc_one(obs, obs_rec):\n",
    "    acc = (((obs > 0.5) == (obs_rec > 0.5)) * 1.0).flatten(start_dim=1).mean()\n",
    "    return acc\n",
    "\n",
    "def rec_loss():\n",
    "    f_pred = dec(obs.flatten(start_dim=1))\n",
    "    obs_rec = rec(f_pred).view(obs.shape[0], *shape)\n",
    "    loss = rec_loss_std(obs, obs_rec)\n",
    "    acc = acc_one(obs, obs_rec)\n",
    "    return {'loss': loss, 'metrics': {'acc': acc.item()}}\n",
    "\n",
    "def fit_loss(force_proba=None, fill_switch_grad=False, detach_features=False,\n",
    "             msw_coeff=1.0):\n",
    "    f_curr = dec(obs.flatten(start_dim=1))\n",
    "    f_next = dec(obs_next.flatten(start_dim=1))\n",
    "    \n",
    "    if detach_features:\n",
    "        f_curr = f_curr.detach()\n",
    "        f_next = f_next.detach()\n",
    "    \n",
    "    detach_rotate = detach_features\n",
    "    f_pred = model(f_curr, force_proba=force_proba, detach_rotate=detach_rotate)\n",
    "    obs_next_pred = rec(f_pred).view(obs.shape[0], *shape)\n",
    "    \n",
    "    delta_f = (f_next - f_pred)\n",
    "    std_f = tensor_std(f_curr)    \n",
    "    delta_f = delta_f / std_f\n",
    "    \n",
    "    loss_fcons = delta_f.pow(2).sum(1)\n",
    "    \n",
    "    loss = rec_loss_std(obs_next, obs_next_pred, nomean=True)\n",
    "    acc = acc_one(obs_next, obs_next_pred)\n",
    "    \n",
    "    loss_total = loss + loss_fcons\n",
    "    \n",
    "    if fill_switch_grad:\n",
    "        manual_switch_gradient(loss_delta_noreduce=loss_total, model=model_,\n",
    "                               loss_scale=msw_coeff)\n",
    "    \n",
    "    loss_total = loss_total.mean(0)# + loss_total.std(0)\n",
    "    \n",
    "    return {\n",
    "        'loss': loss_total,\n",
    "        'metrics': {\n",
    "            'rec': loss.mean(0).item(),\n",
    "            'fcons': loss_fcons.mean(0).item(),\n",
    "            'acc': acc.item()\n",
    "    }}\n",
    "\n",
    "def sparsity_loss():\n",
    "    t = list(model_.model.switch.parameters())[0]\n",
    "    return {'loss': t.abs().sum(), 'metrics': {}}\n",
    "\n",
    "def total_loss(coeffs=None):\n",
    "    if coeffs is None:\n",
    "        coeffs = {}\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    losses = {'rec': rec_loss,\n",
    "              'fit': partial(fit_loss, fill_switch_grad=True, msw_coeff=coeffs['fit']), # need this one, otherwise other features will likely decrease\n",
    "                                                               # the loss, since the probas are 0.5 and features can be duplicated\n",
    "              'fit_half': partial(fit_loss, force_proba=0.5, detach_features=True),\n",
    "              'fit_all': partial(fit_loss, force_proba=1.0, detach_features=True),\n",
    "              'sparsity': sparsity_loss\n",
    "              }\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for key, fcn in losses.items():\n",
    "        data = fcn()\n",
    "        coef = coeffs.get(key, 1.0)\n",
    "        total_loss += data['loss'] * coef\n",
    "        for m_key, m_val in data['metrics'].items():\n",
    "            metrics[f'{m_key}/{key}'] = m_val\n",
    "        metrics[f'loss/{key}'] = data['loss'].item()\n",
    "            \n",
    "    return total_loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_ratio = 1.5\n",
    "sp_min = 1e-9\n",
    "sp_max = 100\n",
    "coeffs = {'rec': 20.0, 'fit': 10.0, 'fit_half': 0.001, 'fit_all': 1.0, 'sparsity': sp_min}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'loss': tensor(0.0077, grad_fn=<MeanBackward1>), 'metrics': {'acc': 1.0}},\n",
       " {'loss': tensor(0.2207, grad_fn=<MeanBackward1>),\n",
       "  'metrics': {'rec': 0.08463115245103836,\n",
       "   'fcons': 0.13605251908302307,\n",
       "   'acc': 0.9998857378959656}},\n",
       " {'loss': tensor(36.0624, grad_fn=<MeanBackward1>),\n",
       "  'metrics': {'rec': 34.36331558227539,\n",
       "   'fcons': 1.6990869045257568,\n",
       "   'acc': 0.8065714240074158}},\n",
       " {'loss': tensor(0.1722, grad_fn=<MeanBackward1>),\n",
       "  'metrics': {'rec': 0.08186542987823486,\n",
       "   'fcons': 0.09038413316011429,\n",
       "   'acc': 1.0}},\n",
       " {'loss': tensor(2.0724, grad_fn=<SumBackward0>), 'metrics': {}})"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_loss(), fit_loss(), fit_loss(force_proba=0.5), fit_loss(force_proba=1.0), sparsity_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCCombinedModel(\n",
       "  (fc01): CombinedLinearLayer()\n",
       "  (fc02): CombinedLinearLayer()\n",
       "  (fc03): CombinedLinearLayer()\n",
       "  (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(list(dec.parameters()) + list(rec.parameters()) + list(model.parameters()),\n",
    "                       lr=1e-4, betas=(0.9, 0.999))\n",
    "# opt_switch = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8547c50b5a4d61981cbc38d948fdcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-696-c154257305f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     if (i // 100) % 2 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/causal/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100000)):\n",
    "    opt.zero_grad()\n",
    "    loss, metrics = total_loss(coeffs)\n",
    "    loss.backward()\n",
    "    \n",
    "#     if (i // 100) % 2 == 0:\n",
    "#         model.switch.probas.grad = None\n",
    "    \n",
    "    opt.step()\n",
    "    \n",
    "#     for _ in range(1):\n",
    "#         opt_switch.zero_grad()\n",
    "#         loss, metrics = total_loss(coeffs)\n",
    "#         loss.backward()\n",
    "#         opt_switch.step()\n",
    "\n",
    "    ratio = metrics['loss/fit'] / metrics['loss/fit_all']\n",
    "    \n",
    "    coeff = coeffs['sparsity']\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        if ratio > crit_ratio or metrics['loss/fit_all'] > 1:\n",
    "            coeff *= 0.5\n",
    "        else:\n",
    "            coeff /= 0.5\n",
    "            \n",
    "        if coeff < sp_min:\n",
    "            coeff = sp_min\n",
    "        elif coeff > sp_max:\n",
    "            coeff = sp_max\n",
    "\n",
    "    coeffs['sparsity'] = coeff\n",
    "    metrics['coeff'] = coeff\n",
    "    metrics['ratio'] = ratio\n",
    "    metrics['loss_total'] = loss.item()\n",
    "\n",
    "    metrics_hist.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_.model.switch.probas.data[:] = 1. * (model_.model.switch.probas > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = lstdct2dctlst(metrics_hist)\n",
    "\n",
    "keys = sorted(metrics_dict.keys())\n",
    "\n",
    "px = 3\n",
    "py = 6\n",
    "\n",
    "assert px * py >= len(keys)\n",
    "\n",
    "plt.figure(figsize=(17, 10))\n",
    "for i, key in enumerate(keys, 1):\n",
    "    plt.subplot(px, py, i)\n",
    "    plt.title(key)\n",
    "    data = metrics_dict[key]\n",
    "    if key.startswith('acc'):\n",
    "        data = np.maximum(np.array(data), 0.99)\n",
    "        plt.axhline(1)\n",
    "    else:\n",
    "        plt.yscale('log')\n",
    "    plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "# S = nn.Softmax(1)(model_.fc1.weight)\n",
    "S = model_.fc1.weight\n",
    "Sinv = torch.pinverse(S)\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.heatmap(S.detach().cpu().numpy())\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.heatmap(Sinv.detach().cpu().numpy())\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap((S @ Sinv).abs().detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MP = model_.model.switch.probas\n",
    "plt.figure(figsize=(15, 5))\n",
    "print(MP)\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(MP.detach().cpu().numpy(), vmin=min_proba, vmax=1)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap((Sinv @ MP @ S).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics_dict['ratio'])\n",
    "plt.yscale('log')\n",
    "plt.plot(pd.Series(metrics_dict['ratio']).rolling(100).median())\n",
    "plt.axhline(crit_ratio)\n",
    "plt.axhline(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics_dict['ratio'])\n",
    "plt.yscale('log')\n",
    "plt.plot(pd.Series(metrics_dict['loss/fit']).rolling(100).median() /\n",
    "         pd.Series(metrics_dict['loss/fit_all']).rolling(100).median())\n",
    "plt.axhline(crit_ratio)\n",
    "plt.axhline(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc -- too bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
