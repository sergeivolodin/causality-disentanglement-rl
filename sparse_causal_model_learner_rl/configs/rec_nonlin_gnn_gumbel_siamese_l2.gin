import sparse_causal_model_learner_rl.trainable.decoder
import sparse_causal_model_learner_rl.trainable.reconstructor
import sparse_causal_model_learner_rl.trainable.model
import sparse_causal_model_learner_rl.trainable.gumbel_switch
import sparse_causal_model_learner_rl.config
import sparse_causal_model_learner_rl.annealer.threshold
import sparse_causal_model_learner_rl.loss.losses
import sparse_causal_model_learner_rl.loss.optimizer
import sparse_causal_model_learner_rl.metrics.nnz
import sparse_causal_model_learner_rl.metrics.loss_thresholded
import sparse_causal_model_learner_rl.metrics.model_entropy
import sparse_causal_model_learner_rl.metrics.metric_smooth
import gin_tune
import sparse_causal_model_learner_rl.trainable.value_predictor
import sparse_causal_model_learner_rl.trainable.fcnet
import sparse_causal_model_learner_rl.learners.input_normalizer
import sparse_causal_model_learner_rl.metrics.context_rewrite
import sparse_causal_model_learner_rl.loss.causal_discriminator
import sparse_causal_model_learner_rl.visual.learner_visual
import sparse_causal_model_learner_rl.trainable.combined
include 'rec_nonlin_gnn.gin'

tune_run.num_samples = 2

Config.loss_every = 1000000000000000

model_gnn/FCCombinedModel.hidden_sizes = [60, 60, 60]
model_gnn/FCCombinedModel.activation_cls = @ReLU

WithInputSwitch.give_mask = True
WithInputSwitch.model_cls = @model_gnn/FCCombinedModel

LearnableSwitch.sample_many = True
LearnableSwitch.sample_threshold = 0.9 # after this value, always sample 1 to prevent vanishing grads

Config.env_steps = 5000
Config.collect_every = 10
Config.batch_training = False
Config.shuffle = False

Config.decoder = @IdentityDecoder
Config.reconstructor = None

WithInputSwitch.switch_cls = @LearnableSwitchSimple

sparse_model/WithInputSwitch.enable_switch = True
non_sparse_model/WithInputSwitch.enable_switch = False

sparse_model/ManyNetworkCombinedModel.model_cls = @sparse_model/WithInputSwitch
non_sparse_model/ManyNetworkCombinedModel.model_cls = @non_sparse_model/WithInputSwitch
ManyNetworkCombinedModel.sparse_do_max = False
ManyNetworkCombinedModel.sparse_do_max_mfma = False

Config.model = @sparse_model/ManyNetworkCombinedModel
Config.non_sparse_model = @non_sparse_model/ManyNetworkCombinedModel

Config.feature_shape = (17, )

opt1/Optimizer.lr = 1e-3
opt2/Optimizer.lr = 1e-3
opt3/Optimizer.lr = 1e-3

opt4/Optimizer.name = 'Adam'
opt4/Optimizer.lr = 1e-3

opt5/Optimizer.name = 'Adam'
opt5/Optimizer.lr = 1e-3

Config.optimizers = {'opt1': @opt1/Optimizer, 'opt2': @opt2/Optimizer, 'opt3': @opt3/Optimizer, 'opt4': @opt4/Optimizer}#, 'opt5': @opt5/Optimizer}
Config.execution = {'opt1': ['fit', 'no_small_probas', 'sparsity'],
                    'opt2': ['fit', 'non_sparse_fit', 'discriminate_siamese', 'fit_all_on'],
                    'opt3': ['non_sparse_fit'],
                    'opt4': ['fit', 'fit_all_on'], # w/o sparsity, only model (for fit)
                    #'opt5': ['discriminate_siamese'],
                    }
Config.optim_params = {'opt1': ['model.switch__params'], # switch learning
                       'opt2': ['decoder'], # representation learning
                       'opt3': ['non_sparse_model.model__params'], # reference model learning
                       'opt4': ['model.model__params'], # model learning
                     #  'opt5': ['decoder'],
                       }
Config.opt_iterations = {'opt1': 3, 'opt2': 5, 'opt3': 3, 'opt4': 4}#, 'opt5': 5,}

smooth.smooth_steps = 20
smooth.do_log = True
fit_loss_smooth/smooth.orig_key = '/fit/value'
non_sparse_fit_loss_smooth/smooth.orig_key = '/non_sparse_fit/value'

mult_sparsity_gap.sparse_key = 'fit_loss_smooth'
mult_sparsity_gap.non_sparse_key = 'non_sparse_fit_loss_smooth'

# using vanilla fit loss
Config.metrics = {'nnz': @nnz, 'threshold_action': @threshold_action,
                  'threshold_features': @threshold_features, 'max_element_ma': @max_element_ma,
                  'max_element_mf': @max_element_mf,
                  'episode_reward': @episode_reward,
                  'graph_entropy_ma': @entropy_action,
                  'graph_entropy_mf': @entropy_features,
                  'threshold_annealer_threshold': @threshold_annealer_threshold,
                  'fit_loss_smooth': @fit_loss_smooth/smooth,
                  'non_sparse_fit_loss_smooth': @non_sparse_fit_loss_smooth/smooth,
                  '|last_mult_sparsity_gap': @mult_sparsity_gap}

MIN_HYPER_ANNEAL = 1e-6

all_on/fit_loss.model_forward_kwargs = {'enable_switch': False}

Config.losses = {'fit': {'fcn': @fit/fit_loss, 'coeff': 1},
                 'sparsity': {'fcn': @sparsity_loss, 'coeff': %MIN_HYPER_ANNEAL},
                 # 'reconstruction': {'fcn': @reconstruction_loss, 'coeff': 1},
                 'non_sparse_fit': {'fcn': @non_sparse_fit_loss/context_rewriter, 'coeff': 1},
                 'discriminate_siamese': {'fcn': @siamese_feature_discriminator_l2, 'coeff': 1000.0},
                 'no_small_probas': {'fcn': @nonzero_proba_loss, 'coeff': 1.0},
                 'fit_all_on': {'fcn': @all_on/fit_loss, 'coeff': 1.0},
                }

fit/fit_loss.fill_switch_grad = True

nonzero_proba_loss.eps = 0.5
nonzero_proba_loss.do_abs = False

non_sparse_fit_loss/context_rewriter.function = @fit_loss
non_sparse_fit_loss/context_rewriter.rewrite = {'model': 'non_sparse_model'}

ThresholdAnnealer.source_metric_key = 'fit_loss_smooth'

entropy_np.return_distribution = True

sch/Scheduler.name = 'ReduceLROnPlateau'
sch/Scheduler.patience = 150
sch/Scheduler.verbose = True
sch/Scheduler.factor = 0.5

Config.schedulers = {
#'opt1': @sch/Scheduler,
                     'opt2': @sch/Scheduler,
                     #'opt3': @sch/Scheduler,
                     }


Config.checkpoint_every = 1000

LearnableSwitch.switch_neg = 0
LearnableSwitch.switch_pos = 0

LearnableSwitchSimple.initial_proba = 0.5
LearnableSwitchSimple.sample_many = True
LearnableSwitchSimple.return_grad = False

ModelResetter.grace_epochs = 250
ModelResetter.reset_optimizers = False
ModelResetter.reset_weights = False
ModelResetter.reset_logits = False
ModelResetter.reset_turn_on = False

Config._update_function = [@AnnealerThresholdSelector, @ThresholdAnnealer, @ModelResetter]

ThresholdAnnealer.adjust_every = 100
ThresholdAnnealer.factor_cool = 0.5
ThresholdAnnealer.factor_heat = 0.001
ThresholdAnnealer.min_hyper = %MIN_HYPER_ANNEAL
ThresholdAnnealer.max_hyper = 10
ThresholdAnnealer.emergency_heating = True
AnnealerThresholdSelector.multiplier = 1
AnnealerThresholdSelector.adjust_every = 20
AnnealerThresholdSelector.source_fit_loss_key = 'non_sparse_fit_loss_smooth'

turn_on_features.loss_fcn = @fit_loss

# normalize input data
Normalizer.once = True
Normalizer.dim = 0
normalize_context_transform.normalize_context_dct = {'obs': ['obs_x', 'obs_y', 'obs'], 'rew_y': ['rew_y'], 'done_y': ['done_y']}
Config.context_transforms = [@normalize_context_transform]

siamese_feature_discriminator_l2.margin = 0.1

Config.report_every = 5
Config.metrics_every = 5

tune_run.resources_per_trial = {'gpu': 0.1, 'cpu': 1}

Config.graph_every = 20

plot_model.vmin = -1.0
plot_model.vmax = 1.0
Config.report_weights = True
Config.report_weights_every = 100

graph_for_matrices.additional_features = %ADDITIONAL_FEATURES
graph_for_matrices.engine = 'dot'
