import sparse_causal_model_learner_rl.trainable.decoder
import sparse_causal_model_learner_rl.trainable.reconstructor
import sparse_causal_model_learner_rl.trainable.model
import sparse_causal_model_learner_rl.config
import sparse_causal_model_learner_rl.annealer.threshold
import sparse_causal_model_learner_rl.loss.losses
import sparse_causal_model_learner_rl.loss.optimizer
import sparse_causal_model_learner_rl.metrics.nnz
import sparse_causal_model_learner_rl.metrics.loss_thresholded
import gin_tune
import sparse_causal_model_learner_rl.trainable.value_predictor
import sparse_causal_model_learner_rl.trainable.fcnet
include 'common.gin'

tune_run.num_samples = 1
tune_run.resources_per_trial = {'gpu': 0, 'cpu': 1}

Config.train_steps = 2000000
Config.env_steps = 1000

Config.loss_every = 1000
Config.graph_every = 500
Config.checkpoint_every = 10000
Config.report_every = 100
Config.metrics_every = 100
Config.report_weights = False

Config.keep_history = True
Config.max_history_size = 1000

LinearDecoder.use_batchnorm = True
LinearDecoder.use_bias = True

Config.model = @LinearModel
Config.decoder = @LinearDecoder
Config.reconstructor = @LinearReconstructor
Config.value_predictor = @ModelValuePredictor

value/FCNet.hidden_sizes = [50, 50, 50, 50]
value/FCNet.activation_cls = @ReLU
ModelValuePredictor.model_cls = @value/FCNet

Config.feature_shape = (5, )

Config._update_function = []

reconstruction_loss_value_function_reward_to_go.value_scaler = 0.1

Config.losses = {'fit': {'fcn': @fit_loss, 'coeff': 1.0},
                 'sparsity': {'fcn': @sparsity_loss, 'coeff': 1e-2},
                 'reconstruction': {'fcn': @reconstruction_loss_value_function_reward_to_go, 'coeff': 1e-3}
                }

opt1/Optimizer.name = 'Adam'
#opt1/Optimizer.lr = 1
#opt1/Optimizer.momentum = 0.9

Config.optimizers = {'opt1': @opt1/Optimizer}
Config.execution = {'opt1': ['fit', 'reconstruction', 'sparsity']}

LinearModel.use_bias = False

sparsity_loss.ord = 1
