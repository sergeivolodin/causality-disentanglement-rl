# Configuration for the causal RL learner

import sparse_causal_model_learner_rl.trainable.decoder
import sparse_causal_model_learner_rl.trainable.reconstructor
import sparse_causal_model_learner_rl.trainable.model
import sparse_causal_model_learner_rl.trainable.value_predictor
import sparse_causal_model_learner_rl.config
import sparse_causal_model_learner_rl.annealer.threshold
import sparse_causal_model_learner_rl.loss.losses
import sparse_causal_model_learner_rl.loss.optimizer
import sparse_causal_model_learner_rl.metrics.nnz
import sparse_causal_model_learner_rl.metrics.graph_threshold
import sparse_causal_model_learner_rl.metrics.max_element
import sparse_causal_model_learner_rl.metrics.episode_reward
import sparse_causal_model_learner_rl.metrics.loss_thresholded
import sparse_causal_model_learner_rl.learners.rl_learner
import gin_tune
include 'base_learner.gin'

Config.shuffle_together = [['obs_x', 'obs_y', 'action_x', 'reward_to_go',
                            'rew_y', 'done_y', 'episode_sum_rewards'],
                           ['obs']]

# a hack, does not work as a reference
Config.learner_cls = "sparse_causal_model_learner_rl.learners.rl_learner.CausalModelLearnerRL"

gin_tune_config.log_sys_usage = True
tune_run.verbose = False
tune_run.resources_per_trial = {'cpu': 1}

Config.train_steps = 20000
Config.env_steps = 1000

Config.loss_every = 500
Config.graph_every = 500
Config.checkpoint_every = 5000
Config.report_every = 20
Config.metrics_every = 20
Config.collect_every = 500
Config.shuffle = False
Config.batch_training = False

Config.keep_history = True
# Config.max_history_size = 10000

LinearDecoder.use_batchnorm = True

Config.model = @LinearModel
Config.decoder = @LinearDecoder
Config.reconstructor = @LinearReconstructor

Config.feature_shape = (30,)

ThresholdAnnealer.fit_threshold = 1e-3
ThresholdAnnealer.factor = 0.5
ThresholdAnnealer.adjust_every = 100

Config._update_function = [@ThresholdAnnealer]

Config.losses = {'fit': {'fcn': @fit_loss, 'coeff': 1.0},
                 'sparsity': {'fcn': @sparsity_loss, 'coeff': 1e-5},
                 'reconstruction': {'fcn': @reconstruction_loss, 'coeff': 1.0}
                }

Config.potential_trainables_list = [
    {'name': 'model', 'description': "Transform current time-step features into next time-step features"},
    {'name': 'decoder', 'description': "Transform high-dimensional observation into low-dimensional features"},
    {'name': 'reconstructor', 'description': "Predict the original observation from features"},
    {'name': 'reconstructor1', 'description': "Second reconstructor"},
    {'name': 'value_predictor', 'description': "Predict value-to-go from the current features"},
    {'name': 'causal_feature_model_discriminator', 'description': "Discriminate between correct and incorrect of pairs (f1, f2)"},
    {'name': 'decoder_discriminator', 'description': "Discriminate between correct and incorrect pairs of (observation, feature)"},
    {'name': 'non_sparse_model', 'description': "A model w/o sparsity constraints used for reference"},
    {'name': 'causal_feature_action_model_discriminator', 'description': "Discriminate between correct triplets (f1, a1, f2) and incorrect ones. Takes additional features as well for the second argument."},
    {'name': 'rot_pre', 'description': "Transform decoder features to model features"},
    {'name': 'rot_post', 'description': "Transform model features to decoder features"},
    {'name': 'lagrange_multipliers', 'description': "Lagrange multipliers for constrained optimization"},
]

loss_thresholded.eps = 1e-3
loss_thresholded.loss = @fit_loss
loss_thresholded.delta = False

nnz.eps = 1e-3
Config.metrics = {'nnz': @nnz, 'with_sparse_fit': @loss_thresholded, 'threshold_action': @threshold_action,
                  'threshold_features': @threshold_features, 'max_element_ma': @max_element_ma, 'max_element_mf': @max_element_mf,
                  'episode_reward': @episode_reward}

opt1/Optimizer.name = 'Adam'
opt1/Optimizer.lr = 1e-3

Config.optimizers = {'opt1': @opt1/Optimizer}
Config.execution = {'opt1': ['fit', 'sparsity', 'reconstruction']}

LinearModel.use_bias = False

tune_run.verbose = True
tune_run.queue_trials = True

sparsity_loss.ord = 1
